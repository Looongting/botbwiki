"""
ç¾¤æ¶ˆæ¯æ€»ç»“æ’ä»¶
åŠŸèƒ½ï¼š
1. é€šè¿‡HTTP APIè·å–æŒ‡å®šç¾¤çš„æŒ‡å®šæ—¥æœŸçš„å†å²èŠå¤©è®°å½•
2. å°†èŠå¤©è®°å½•æ•´åˆä¸ºæ˜“äºAIè¯»å–çš„æ ¼å¼ï¼Œå¹¶ä»¥ç¾¤èŠid-æ—¥æœŸçš„å½¢å¼ä¿å­˜åˆ°./data/historyè·¯å¾„
3. å°†æŒ‡å®šèŠå¤©è®°å½•å‘é€ç»™AIï¼Œè¦æ±‚å®ƒæŒ‰æŒ‡å®šæ ¼å¼æ•´ç†èŠå¤©å†…å®¹é‡Œçš„æŠ€æœ¯ç­”ç–‘å’ŒçŸ¥è¯†å…±äº«å†…å®¹
4. æ¥æ”¶AIçš„å›å¤å¹¶ç”Ÿæˆæ–‡ä»¶å‚¨å­˜åˆ°./data/historySummary
"""

import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from nonebot import on_command
from nonebot.adapters.onebot.v11 import GroupMessageEvent
from nonebot.log import logger
from nonebot.params import CommandArg
from nonebot.rule import to_me, Rule

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.core.config import config
from src.core.http_client import get_client
from src.core.ai_manager import ai_manager
from src.core.message_sender import get_sender


# åˆ›å»ºæ•°æ®ç›®å½•
def ensure_data_dirs():
    """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
    os.makedirs("./data/history", exist_ok=True)
    os.makedirs("./data/daySummary", exist_ok=True)


# å‘½ä»¤å¤„ç†å™¨
summary_cmd = on_command("ç¾¤æ€»ç»“", rule=to_me(), priority=5)


@summary_cmd.handle()
async def handle_summary_command(event: GroupMessageEvent, args=CommandArg()):
    """å¤„ç†ç¾¤æ€»ç»“å‘½ä»¤"""
    try:
        # è§£æå‚æ•°
        arg_str = str(args).strip()
        
        if not arg_str:
            # é»˜è®¤æ€»ç»“æ˜¨å¤©çš„æ¶ˆæ¯
            target_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        else:
            # è§£ææ—¥æœŸå‚æ•°
            try:
                if arg_str == "ä»Šå¤©":
                    target_date = datetime.now().strftime("%Y-%m-%d")
                elif arg_str == "æ˜¨å¤©":
                    target_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
                else:
                    # å°è¯•è§£ææ—¥æœŸæ ¼å¼ YYYY-MM-DD
                    datetime.strptime(arg_str, "%Y-%m-%d")
                    target_date = arg_str
            except ValueError:
                logger.error("æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ï¼Œæˆ–ä½¿ç”¨'ä»Šå¤©'ã€'æ˜¨å¤©'")
                return
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        ensure_data_dirs()
        
        # æ‰§è¡Œæ€»ç»“æµç¨‹
        result = await process_group_summary(event.group_id, target_date)
        
        if result["success"]:
            summary_file = result["summary_file"]
            logger.info(f"ç¾¤æ¶ˆæ¯æ€»ç»“å®Œæˆï¼Œæ–‡ä»¶ä¿å­˜åˆ°: {summary_file}")
        else:
            logger.error(f"ç¾¤æ¶ˆæ¯æ€»ç»“å¤±è´¥: {result['error']}")
            
    except Exception as e:
        logger.error(f"ç¾¤æ€»ç»“å‘½ä»¤å¤„ç†å¼‚å¸¸: {e}")


async def process_group_summary(group_id: int, target_date: str) -> Dict[str, Any]:
    """
    å¤„ç†ç¾¤æ¶ˆæ¯æ€»ç»“çš„å®Œæ•´æµç¨‹
    
    Args:
        group_id: ç¾¤ID
        target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)
        
    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    try:
        # 1. è·å–ç¾¤èŠå†å²è®°å½•
        logger.info(f"å¼€å§‹è·å–ç¾¤ {group_id} åœ¨ {target_date} çš„å†å²æ¶ˆæ¯")
        history_data = await fetch_group_history(group_id, target_date)
        
        if not history_data["success"]:
            return {"success": False, "error": f"è·å–å†å²æ¶ˆæ¯å¤±è´¥: {history_data['error']}"}
        
        # 2. ä¿å­˜ä¼˜åŒ–åçš„å†å²è®°å½•
        history_file = f"./data/history/{group_id}-{target_date}.json"
        try:
            optimized_data = optimize_message_data(history_data["data"])
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(optimized_data, f, ensure_ascii=False, indent=2)
            logger.info(f"å†å²æ¶ˆæ¯å·²ä¿å­˜åˆ°: {history_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜å†å²æ¶ˆæ¯æ–‡ä»¶å¤±è´¥: {e}")
            # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œä¿å­˜åŸå§‹æ•°æ®
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history_data["data"], f, ensure_ascii=False, indent=2)
            logger.info(f"å·²ä¿å­˜åŸå§‹å†å²æ¶ˆæ¯åˆ°: {history_file}")
        
        # 3. æ ¼å¼åŒ–èŠå¤©è®°å½•ä¸ºAIå¯è¯»æ ¼å¼
        formatted_messages = format_messages_for_ai(history_data["data"])
        
        # 4. è°ƒç”¨AIè¿›è¡Œæ€»ç»“
        logger.info("å¼€å§‹è°ƒç”¨AIè¿›è¡Œæ¶ˆæ¯æ€»ç»“")
        ai_result = await call_ai_for_summary(formatted_messages)
        
        if not ai_result["success"]:
            return {"success": False, "error": f"AIæ€»ç»“å¤±è´¥: {ai_result['error']}"}
        
        # 5. ä¿å­˜AIæ€»ç»“ç»“æœ
        summary_file = f"./data/daySummary/{group_id}-{target_date}-summary.json"
        summary_data = {
            "group_id": group_id,
            "date": target_date,
            "summary": ai_result["data"],
            "created_at": datetime.now().isoformat(),
            "message_count": len(history_data["data"])
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"AIæ€»ç»“å·²ä¿å­˜åˆ°: {summary_file}")
        
        return {
            "success": True,
            "history_file": history_file,
            "summary_file": summary_file,
            "message_count": len(history_data["data"])
        }
        
    except Exception as e:
        logger.error(f"ç¾¤æ¶ˆæ¯æ€»ç»“å¤„ç†å¼‚å¸¸: {e}")
        return {"success": False, "error": str(e)}


async def fetch_group_history(group_id: int, target_date: str) -> Dict[str, Any]:
    """
    è·å–ç¾¤èŠå†å²è®°å½•
    
    Args:
        group_id: ç¾¤ID
        target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)
        
    Returns:
        è·å–ç»“æœå­—å…¸
    """
    try:
        client = get_client()
        
        # è®¡ç®—ç›®æ ‡æ—¥æœŸçš„æ—¶é—´èŒƒå›´
        target_datetime = datetime.strptime(target_date, "%Y-%m-%d")
        
        # è®¡ç®—ç›®æ ‡æ—¥æœŸçš„å¼€å§‹å’Œç»“æŸæ—¶é—´æˆ³ï¼ˆæœ¬åœ°æ—¶é—´ï¼‰
        start_time = int(target_datetime.timestamp())
        end_time = int((target_datetime + timedelta(days=1)).timestamp())
        
        logger.info(f"è·å–ç¾¤ {group_id} ä» {start_time} åˆ° {end_time} çš„æ¶ˆæ¯")
        logger.info(f"æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(start_time)} åˆ° {datetime.fromtimestamp(end_time)}")
        
        # è·å–ç¾¤æ¶ˆæ¯å†å² - ä½¿ç”¨message_idå‚æ•°æ¥è·å–æ›´å¤šå†å²æ¶ˆæ¯
        all_messages = []
        message_id = None
        max_attempts = 10  # æœ€å¤šå°è¯•10æ¬¡ï¼Œé¿å…æ— é™å¾ªç¯
        
        for attempt in range(max_attempts):
            logger.info(f"å°è¯•è·å–å†å²æ¶ˆæ¯ï¼Œç¬¬ {attempt + 1} æ¬¡ï¼Œmessage_id: {message_id}")
            
            result = await client.get_group_msg_history(group_id, message_id, 50)  # æ¯æ¬¡è·å–50æ¡æ¶ˆæ¯
            
            if result.get("status") != "ok":
                logger.warning(f"è·å–æ¶ˆæ¯å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                break
            
            messages = result.get("data", {}).get("messages", [])
            if not messages:
                logger.info("æ²¡æœ‰æ›´å¤šæ¶ˆæ¯äº†")
                break
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»è·å–åˆ°ç›®æ ‡æ—¥æœŸä¹‹å‰çš„æ¶ˆæ¯
            oldest_msg_time = min(msg.get("time", 0) for msg in messages)
            oldest_msg_date = datetime.fromtimestamp(oldest_msg_time)
            
            logger.info(f"æœ¬æ¬¡è·å–åˆ° {len(messages)} æ¡æ¶ˆæ¯ï¼Œæœ€æ—©æ¶ˆæ¯æ—¶é—´: {oldest_msg_date}")
            
            all_messages.extend(messages)
            
            # å¦‚æœæœ€æ—©çš„æ¶ˆæ¯å·²ç»æ—©äºç›®æ ‡æ—¥æœŸï¼Œåœæ­¢è·å–
            if oldest_msg_time < start_time:
                logger.info(f"å·²è·å–åˆ°ç›®æ ‡æ—¥æœŸä¹‹å‰çš„æ¶ˆæ¯ï¼Œåœæ­¢è·å–")
                break
            
            # æ›´æ–°message_idä¸ºæœ€æ—©æ¶ˆæ¯çš„IDï¼Œç»§ç»­è·å–æ›´æ—©çš„æ¶ˆæ¯
            oldest_message = min(messages, key=lambda msg: msg.get("time", 0))
            message_id = str(oldest_message.get("message_id", ""))
            if not message_id or message_id == "0":
                logger.info("æ— æ³•è·å–æ›´æ—©çš„æ¶ˆæ¯")
                break
        
        logger.info(f"æ€»å…±è·å–åˆ° {len(all_messages)} æ¡å†å²æ¶ˆæ¯")
        
        # è¿‡æ»¤æŒ‡å®šæ—¥æœŸçš„æ¶ˆæ¯
        filtered_messages = []
        for msg in all_messages:
            msg_time = msg.get("time", 0)
            if start_time <= msg_time < end_time:
                filtered_messages.append(msg)
        
        logger.info(f"æ‰¾åˆ° {len(filtered_messages)} æ¡ {target_date} çš„æ¶ˆæ¯")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›®æ ‡æ—¥æœŸçš„æ¶ˆæ¯ï¼Œè®°å½•ä¸€äº›è°ƒè¯•ä¿¡æ¯
        if not filtered_messages and all_messages:
            logger.warning(f"æœªæ‰¾åˆ° {target_date} çš„æ¶ˆæ¯ï¼Œä½†è·å–åˆ°äº† {len(all_messages)} æ¡å†å²æ¶ˆæ¯")
            # æ˜¾ç¤ºæœ€è¿‘å‡ æ¡æ¶ˆæ¯çš„æ—¶é—´ä¿¡æ¯
            for i, msg in enumerate(all_messages[:5]):
                msg_time = msg.get("time", 0)
                msg_date = datetime.fromtimestamp(msg_time)
                logger.info(f"æ¶ˆæ¯ {i+1}: {msg_date} - {msg.get('raw_message', '')[:50]}")
        
        return {
            "success": True,
            "data": filtered_messages
        }
        
    except Exception as e:
        logger.error(f"è·å–ç¾¤å†å²æ¶ˆæ¯å¼‚å¸¸: {e}")
        return {"success": False, "error": str(e)}


def optimize_message_data(messages: List[Dict[str, Any]]) -> Dict[str, str]:
    """
    ä¼˜åŒ–æ¶ˆæ¯æ•°æ®æ ¼å¼ï¼Œä½¿ç”¨message_idä½œä¸ºkeyï¼Œraw_messageä½œä¸ºå€¼
    
    Args:
        messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
        
    Returns:
        ä¼˜åŒ–åçš„æ¶ˆæ¯å­—å…¸
    """
    optimized = {}
    
    for msg in messages:
        # è·å–æ¶ˆæ¯ID
        message_id = msg.get("message_id")
        if message_id is None:
            continue
            
        # è·å–æ¶ˆæ¯å†…å®¹
        raw_message = msg.get("raw_message", "").strip()
        
        # è·³è¿‡ç©ºæ¶ˆæ¯
        if not raw_message:
            continue
            
        # ä½¿ç”¨message_idä½œä¸ºkey
        optimized[str(message_id)] = raw_message
    
    return optimized


def format_messages_for_ai(messages: List[Dict[str, Any]]) -> str:
    """
    å°†æ¶ˆæ¯æ ¼å¼åŒ–ä¸ºAIå¯è¯»çš„æ ¼å¼ï¼Œä¼˜åŒ–tokenä½¿ç”¨
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        
    Returns:
        æ ¼å¼åŒ–åçš„æ¶ˆæ¯æ–‡æœ¬
    """
    formatted_lines = []
    
    for msg in messages:
        # æå–æ¶ˆæ¯ä¿¡æ¯
        user_id = msg.get("user_id", "æœªçŸ¥ç”¨æˆ·")
        content = msg.get("raw_message", "").strip()
        
        # è·³è¿‡ç©ºæ¶ˆæ¯
        if not content:
            continue
            
        # è·³è¿‡æœºå™¨äººè‡ªå·±çš„æ¶ˆæ¯ï¼ˆé¿å…å¾ªç¯ï¼‰
        if user_id == 3330219965:  # æœºå™¨äººè‡ªå·±çš„ID
            continue
            
        # è·³è¿‡çº¯è¡¨æƒ…åŒ…å’Œå›¾ç‰‡æ¶ˆæ¯
        if (content.startswith("[CQ:image") or 
            content.startswith("[CQ:forward") or
            content in ["ï¼Ÿ", "ã€‚", "ï¼", "?", ".", "!"] or
            len(content) < 2):
            continue
            
        # è·³è¿‡AIè§¦å‘è¯æ¶ˆæ¯ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        if content.startswith("?ai "):
            # æå–é—®é¢˜éƒ¨åˆ†
            question = content[4:].strip()
            if question:
                formatted_lines.append(f"ç”¨æˆ·{user_id}: {question}")
            continue
            
        # è·³è¿‡AIå›å¤ç›¸å…³çš„æ¶ˆæ¯
        if content in ["ğŸ¤– AIæ­£åœ¨æ€è€ƒ...", "è¯·æŸ¥æ”¶", "å·²æˆªæ–­"]:
            continue
            
        # åªä¿ç•™æœ‰æ„ä¹‰çš„æ–‡æœ¬æ¶ˆæ¯
        if content and len(content) > 1:
            formatted_lines.append(f"ç”¨æˆ·{user_id}: {content}")
    
    return "\n".join(formatted_lines)


async def call_ai_for_summary(formatted_messages: str) -> Dict[str, Any]:
    """
    è°ƒç”¨AIè¿›è¡Œæ¶ˆæ¯æ€»ç»“
    
    Args:
        formatted_messages: æ ¼å¼åŒ–çš„æ¶ˆæ¯æ–‡æœ¬
        
    Returns:
        AIå¤„ç†ç»“æœå­—å…¸
    """
    try:
        # æ„å»ºAIæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯å†…å®¹åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹ç¾¤èŠè®°å½•ï¼Œæå–å…¶ä¸­çš„æŠ€æœ¯ç­”ç–‘å’ŒçŸ¥è¯†å…±äº«å†…å®¹ã€‚

åˆ†æè¦æ±‚ï¼š
1. è¯†åˆ«æ‰€æœ‰æŠ€æœ¯ç›¸å…³çš„è®¨è®ºå†…å®¹ï¼ˆç¼–ç¨‹ã€å·¥å…·ä½¿ç”¨ã€é—®é¢˜è§£å†³ç­‰ï¼‰
2. å°†ç›¸åŒä¸»é¢˜çš„å†…å®¹åˆå¹¶åˆ°ä¸€èµ·
3. æå–å…·ä½“çš„è§£å†³æ–¹æ¡ˆã€å»ºè®®å’ŒçŸ¥è¯†ç‚¹
4. å¿½ç•¥çº¯é—²èŠã€è¡¨æƒ…åŒ…ã€é—®å€™ç­‰éæŠ€æœ¯å†…å®¹
5. æ¯ä¸ªä¸»é¢˜è¦åŒ…å«æ¸…æ™°çš„åç§°å’Œå…·ä½“çš„æ–¹æ¡ˆåˆ—è¡¨

ç¾¤èŠè®°å½•ï¼š
{formatted_messages}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
[
  {{
    "name": "å…·ä½“çš„æŠ€æœ¯ä¸»é¢˜åç§°",
    "æ–¹æ¡ˆ": [
      "å…·ä½“çš„è§£å†³æ–¹æ¡ˆæˆ–çŸ¥è¯†ç‚¹1",
      "å…·ä½“çš„è§£å†³æ–¹æ¡ˆæˆ–çŸ¥è¯†ç‚¹2"
    ]
  }}
]

å¦‚æœç¾¤èŠä¸­æ²¡æœ‰æŠ€æœ¯å†…å®¹ï¼Œè¯·è¿”å›ç©ºæ•°ç»„ï¼š[]"""

        # è°ƒç”¨AI
        messages = [
            {"role": "user", "content": prompt}
        ]
        
        result = await ai_manager.chat_completion(messages)
        
        if not result:
            return {"success": False, "error": "AIæœåŠ¡è°ƒç”¨å¤±è´¥"}
        
        # å°è¯•è§£æAIè¿”å›çš„JSON
        try:
            # æ¸…ç†AIè¿”å›çš„å†…å®¹ï¼Œæå–JSONéƒ¨åˆ†
            json_start = result.find('[')
            json_end = result.rfind(']') + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = result[json_start:json_end]
                parsed_data = json.loads(json_str)
                
                return {
                    "success": True,
                    "data": parsed_data
                }
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°JSONæ ¼å¼ï¼Œè¿”å›åŸå§‹ç»“æœ
                return {
                    "success": True,
                    "data": [{"name": "AIæ€»ç»“", "æ–¹æ¡ˆ": [result]}]
                }
                
        except json.JSONDecodeError as e:
            logger.warning(f"AIè¿”å›å†…å®¹JSONè§£æå¤±è´¥: {e}")
            # JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ
            return {
                "success": True,
                "data": [{"name": "AIæ€»ç»“", "æ–¹æ¡ˆ": [result]}]
            }
        
    except Exception as e:
        logger.error(f"AIæ€»ç»“è°ƒç”¨å¼‚å¸¸: {e}")
        return {"success": False, "error": str(e)}


# æ‰¹é‡æ€»ç»“å‘½ä»¤
batch_summary_cmd = on_command("æ‰¹é‡æ€»ç»“", rule=to_me(), priority=5)


@batch_summary_cmd.handle()
async def handle_batch_summary_command(event: GroupMessageEvent, args=CommandArg()):
    """å¤„ç†æ‰¹é‡æ€»ç»“å‘½ä»¤"""
    try:
        arg_str = str(args).strip()
        
        if not arg_str:
            logger.error("è¯·æŒ‡å®šè¦æ€»ç»“çš„å¤©æ•°ï¼Œä¾‹å¦‚ï¼šæ‰¹é‡æ€»ç»“ 7")
            return
        
        try:
            days = int(arg_str)
            if days <= 0 or days > 30:
                logger.error("å¤©æ•°å¿…é¡»åœ¨1-30ä¹‹é—´")
                return
        except ValueError:
            logger.error("å¤©æ•°å¿…é¡»æ˜¯æ•°å­—")
            return
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        ensure_data_dirs()
        
        logger.info(f"å¼€å§‹æ‰¹é‡æ€»ç»“æœ€è¿‘ {days} å¤©çš„ç¾¤æ¶ˆæ¯")
        
        # æ‰¹é‡å¤„ç†
        success_count = 0
        failed_dates = []
        
        for i in range(days):
            target_date = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
            
            try:
                result = await process_group_summary(event.group_id, target_date)
                if result["success"]:
                    success_count += 1
                    logger.info(f"æˆåŠŸæ€»ç»“ {target_date} çš„æ¶ˆæ¯")
                else:
                    failed_dates.append(f"{target_date}: {result['error']}")
                    logger.warning(f"æ€»ç»“ {target_date} å¤±è´¥: {result['error']}")
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                await asyncio.sleep(1)
                
            except Exception as e:
                failed_dates.append(f"{target_date}: {str(e)}")
                logger.error(f"æ€»ç»“ {target_date} å¼‚å¸¸: {e}")
        
        # è®°å½•ç»“æœ
        logger.info(f"æ‰¹é‡æ€»ç»“å®Œæˆï¼æˆåŠŸ: {success_count} å¤©")
        if failed_dates:
            logger.warning(f"å¤±è´¥: {len(failed_dates)} å¤©")
            if len(failed_dates) <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªå¤±è´¥é¡¹
                logger.warning(f"å¤±è´¥è¯¦æƒ…: {'\n'.join(failed_dates[:5])}")
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æ€»ç»“å‘½ä»¤å¤„ç†å¼‚å¸¸: {e}")


# æ—¥æ€»ç»“å‘½ä»¤
def is_target_group() -> Rule:
    """æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡ç¾¤ä¸­"""
    def _check(event: GroupMessageEvent) -> bool:
        return event.group_id in config.TARGET_GROUP_IDS
    return Rule(_check)

day_summary_cmd = on_command("ai_daySum", rule=is_target_group(), priority=5)


@day_summary_cmd.handle()
async def handle_day_summary_command(event: GroupMessageEvent, args=CommandArg()):
    """å¤„ç†æ—¥æ€»ç»“å‘½ä»¤"""
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„ç¾¤ä¸­
        if event.group_id not in config.TARGET_GROUP_IDS:
            return
        
        arg_str = str(args).strip()
        
        if not arg_str:
            # é»˜è®¤æ€»ç»“ä»Šå¤©çš„æ¶ˆæ¯
            target_date = datetime.now().strftime("%Y-%m-%d")
        else:
            # è§£ææ—¥æœŸå‚æ•°
            try:
                if arg_str == "ä»Šå¤©":
                    target_date = datetime.now().strftime("%Y-%m-%d")
                elif arg_str == "æ˜¨å¤©":
                    target_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
                else:
                    # å°è¯•è§£ææ—¥æœŸæ ¼å¼ YYYYMMDD
                    if len(arg_str) == 8 and arg_str.isdigit():
                        # æ ¼å¼ï¼š20250925 -> 2025-09-25
                        year = arg_str[:4]
                        month = arg_str[4:6]
                        day = arg_str[6:8]
                        target_date = f"{year}-{month}-{day}"
                        # éªŒè¯æ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
                        datetime.strptime(target_date, "%Y-%m-%d")
                    else:
                        # å°è¯•è§£ææ ‡å‡†æ—¥æœŸæ ¼å¼ YYYY-MM-DD
                        datetime.strptime(arg_str, "%Y-%m-%d")
                        target_date = arg_str
            except ValueError:
                logger.error("æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYYMMDD æ ¼å¼ï¼ˆå¦‚20250925ï¼‰ï¼Œæˆ–ä½¿ç”¨'ä»Šå¤©'ã€'æ˜¨å¤©'")
                return
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        ensure_data_dirs()
        
        # æ‰§è¡Œæ€»ç»“æµç¨‹
        result = await process_group_summary(event.group_id, target_date)
        
        if result["success"]:
            summary_file = result["summary_file"]
            message_count = result["message_count"]
            logger.info(f"ç¾¤æ¶ˆæ¯æ€»ç»“å®Œæˆï¼å¤„ç†äº† {message_count} æ¡æ¶ˆæ¯ï¼Œæ–‡ä»¶ä¿å­˜åˆ°: {summary_file}")
        else:
            logger.error(f"ç¾¤æ¶ˆæ¯æ€»ç»“å¤±è´¥: {result['error']}")
            
    except Exception as e:
        logger.error(f"æ—¥æ€»ç»“å‘½ä»¤å¤„ç†å¼‚å¸¸: {e}")


# æŸ¥çœ‹æ€»ç»“å‘½ä»¤
view_summary_cmd = on_command("æŸ¥çœ‹æ€»ç»“", rule=to_me(), priority=5)


@view_summary_cmd.handle()
async def handle_view_summary_command(event: GroupMessageEvent, args=CommandArg()):
    """å¤„ç†æŸ¥çœ‹æ€»ç»“å‘½ä»¤"""
    try:
        arg_str = str(args).strip()
        
        if not arg_str:
            # é»˜è®¤æŸ¥çœ‹æ˜¨å¤©çš„æ€»ç»“
            target_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        else:
            try:
                if arg_str == "ä»Šå¤©":
                    target_date = datetime.now().strftime("%Y-%m-%d")
                elif arg_str == "æ˜¨å¤©":
                    target_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
                else:
                    datetime.strptime(arg_str, "%Y-%m-%d")
                    target_date = arg_str
            except ValueError:
                logger.error("æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ï¼Œæˆ–ä½¿ç”¨'ä»Šå¤©'ã€'æ˜¨å¤©'")
                return
        
        # æŸ¥æ‰¾æ€»ç»“æ–‡ä»¶
        summary_file = f"./data/daySummary/{event.group_id}-{target_date}-summary.json"
        
        if not os.path.exists(summary_file):
            logger.warning(f"æœªæ‰¾åˆ° {target_date} çš„æ€»ç»“æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œç¾¤æ€»ç»“å‘½ä»¤")
            return
        
        # è¯»å–å¹¶æ˜¾ç¤ºæ€»ç»“
        try:
            with open(summary_file, 'r', encoding='utf-8') as f:
                summary_data = json.load(f)
            
            summary_content = summary_data.get("summary", [])
            message_count = summary_data.get("message_count", 0)
            
            if not summary_content:
                logger.info(f"{target_date} çš„æ€»ç»“ä¸ºç©º")
                return
            
            # æ ¼å¼åŒ–æ˜¾ç¤º
            display_text = f"ğŸ“Š {target_date} ç¾¤æ¶ˆæ¯æ€»ç»“ (å…±{message_count}æ¡æ¶ˆæ¯)\n\n"
            
            for i, item in enumerate(summary_content, 1):
                name = item.get("name", "æœªçŸ¥ä¸»é¢˜")
                solutions = item.get("æ–¹æ¡ˆ", [])
                
                display_text += f"{i}. {name}\n"
                for j, solution in enumerate(solutions, 1):
                    display_text += f"   {j}) {solution}\n"
                display_text += "\n"
            
            # è®°å½•æ€»ç»“å†…å®¹åˆ°æ—¥å¿—
            logger.info(f"æŸ¥çœ‹æ€»ç»“å†…å®¹: {display_text}")
            
        except Exception as e:
            logger.error(f"è¯»å–æ€»ç»“æ–‡ä»¶å¼‚å¸¸: {e}")
            
    except Exception as e:
        logger.error(f"æŸ¥çœ‹æ€»ç»“å‘½ä»¤å¤„ç†å¼‚å¸¸: {e}")
